{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 03: Filtering, Sorting, and Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following up on the last activity, we are asked to deliver some more complex operations.   \n",
    "We will, therefore, continue to work with the same dataset, our `normal_distribution.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary dependencies\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Dataset\n",
    "dataset = np.genfromtxt('./data/normal_distribution.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get better insights into our dataset, we want to only look at the value that fulfills certain conditions.   \n",
    "Our client reaches out to us and asks us to provide lists of values that fulfills these conditions:\n",
    "- all values greater than 95 (>95)\n",
    "- all values that are between 80 and 95 (>80 and <95)\n",
    "- the indices of all values that have a delta of less than 1 to 100 (x-100 < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.,  96., 100.,  97., 100., 100.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values that are greater than 105\n",
    "dataset[dataset>95]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85., 90., 82., 85., 90., 90., 90., 81., 82., 82., 87., 87., 83.,\n",
       "       82., 89.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values that are between 80 and 95\n",
    "dataset[(dataset>80) & (dataset<95)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:**    \n",
    "Conditional filtering can be done either using the brackets syntax or NumPys `extract` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution-1:\n",
      "row is : [2 3 4 5]\n",
      "col is : [2 2 7 7]\n",
      "[[2, 2], [3, 2], [4, 7], [5, 7]]\n",
      "Solution-2:\n",
      "[[2, 2], [3, 2], [4, 7], [5, 7]]\n"
     ]
    }
   ],
   "source": [
    "# indices of values that have a delta of less than 1 to 100\n",
    "\n",
    "#Solution-1\n",
    "print(\"Solution-1:\")\n",
    "rows, cols = np.where(dataset == 100)  \n",
    "print('row is :',rows)\n",
    "print('col is :',cols)\n",
    "\n",
    "my_list = []\n",
    "\n",
    "\n",
    "# for (index,data) in np.ndenumerate(rows):       # Since we have no business with data, we can use _ (throaway variable)\n",
    "for (index,_) in np.ndenumerate(rows):\n",
    "     my_list.append([rows[index],cols[index]])\n",
    "\n",
    "        \n",
    "print(my_list)\n",
    "    \n",
    "#Solution-2\n",
    "print(\"Solution-2:\")\n",
    "one_away_indices = [[rows[index], cols[index]] for (index, _) in np.ndenumerate(rows)]\n",
    "print(one_away_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They also want to experiment with some more plotting techniques so they ask you to also deliver these datasets:\n",
    "- values sorted in ascending order for each row\n",
    "- values sorted in ascending order for each column\n",
    "- the matrix of indices indicating the position in a sorted list of each value   \n",
    "```\n",
    "[3, 1, 2, 5, 4]  =>  [1, 2, 0, 4, 3]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59.  65.  71.  72.  75.  75.  85.  90.]\n",
      " [ 65.  71.  71.  75.  80.  82.  85.  90.]\n",
      " [ 59.  61.  75.  80.  90.  90.  96. 100.]\n",
      " [ 63.  64.  77.  81.  82.  95.  97. 100.]\n",
      " [ 65.  67.  69.  72.  82.  87.  87. 100.]\n",
      " [ 58.  75.  76.  79.  82.  83.  89. 100.]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# values sorted for each row\n",
    "rows_sorted = np.sort(dataset,axis=1)\n",
    "print(rows_sorted)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:**   \n",
    "By default, sorting will always be done along the last axis. In our case this is 1, leading to each row being sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values sorted for each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of positions for each row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finishing their visualization and doing ask you to deliver a way they can incrementally add the split parts of the dataset to make sure it works with every subset, too.   \n",
    "They want you to send them examples for:\n",
    "- adding the second half of the first column\n",
    "- adding the second column\n",
    "- adding the third and last separate column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array split does not result in an equal division",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-27c1af93ca13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# split up dataset from activity03\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mthirds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhalfed_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthirds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# this is the part we've sent the client in activity03\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhsplit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mhsplit\u001b[1;34m(ary, indices_or_sections)\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hsplit only works on arrays of 1 or more dimensions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msplit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    873\u001b[0m                 'array split does not result in an equal division') from None\n\u001b[0;32m    874\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array split does not result in an equal division"
     ]
    }
   ],
   "source": [
    "# split up dataset from activity03\n",
    "thirds = np.hsplit(dataset, (3))\n",
    "halfed_first = np.vsplit(thirds[0], (2))\n",
    "\n",
    "# this is the part we've sent the client in activity03\n",
    "halfed_first[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the second half of the first column to the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the second column to our combined dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the third column to our combined dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:**    \n",
    "The same results can be achieved with `np.concatenate` and `np.stack`.    \n",
    "For both methods, you need to provide the axis onto which it should be appended.   \n",
    "Depending on your preferences you might want to use those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For their internal AI algorithms, they need the dataset in a reshaped manner that reduces the number of columns.   \n",
    "They asked us to deliver the whole dataset in the following shapes:\n",
    "- reshaped in a one-dimensional list with all values\n",
    "- reshaped in a matrix with only 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping to a list of values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping to a matrix with two columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:**   \n",
    "-1 in the dimension definition means that it figures out the other dimension on its own"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
